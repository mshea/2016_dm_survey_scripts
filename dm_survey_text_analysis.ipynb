{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas\n",
    "stopwords = [\"a\",\"able\",\"about\",\"above\",\"abst\",\"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\"actually\",\"added\",\"adj\",\"affected\",\"affecting\",\"affects\",\"after\",\"afterwards\",\"again\",\"against\",\"ah\",\"all\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"am\",\"among\",\"amongst\",\"an\",\"and\",\"announce\",\"another\",\"any\",\"anybody\",\"anyhow\",\"anymore\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apparently\",\"approximately\",\"are\",\"aren\",\"arent\",\"arise\",\"around\",\"as\",\"aside\",\"ask\",\"asking\",\"at\",\"auth\",\"available\",\"away\",\"awfully\",\"b\",\"back\",\"be\",\"became\",\"because\",\"become\",\"becomes\",\"becoming\",\"been\",\"before\",\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\"behind\",\"being\",\"believe\",\"below\",\"beside\",\"besides\",\"between\",\"beyond\",\"biol\",\"both\",\"brief\",\"briefly\",\"but\",\"by\",\"c\",\"ca\",\"came\",\"can\",\"cannot\",\"can't\",\"cause\",\"causes\",\"certain\",\"certainly\",\"co\",\"com\",\"come\",\"comes\",\"contain\",\"containing\",\"contains\",\"could\",\"couldnt\",\"d\",\"date\",\"did\",\"didn't\",\"different\",\"do\",\"does\",\"doesn't\",\"doing\",\"done\",\"don't\",\"down\",\"downwards\",\"due\",\"during\",\"e\",\"each\",\"ed\",\"edu\",\"effect\",\"eg\",\"eight\",\"eighty\",\"either\",\"else\",\"elsewhere\",\"end\",\"ending\",\"enough\",\"especially\",\"et\",\"et-al\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"except\",\"f\",\"far\",\"few\",\"ff\",\"fifth\",\"first\",\"five\",\"fix\",\"followed\",\"following\",\"follows\",\"for\",\"former\",\"formerly\",\"forth\",\"found\",\"four\",\"from\",\"further\",\"furthermore\",\"g\",\"gave\",\"get\",\"gets\",\"getting\",\"give\",\"given\",\"gives\",\"giving\",\"go\",\"goes\",\"gone\",\"got\",\"gotten\",\"h\",\"had\",\"happens\",\"hardly\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"hed\",\"hence\",\"her\",\"here\",\"hereafter\",\"hereby\",\"herein\",\"heres\",\"hereupon\",\"hers\",\"herself\",\"hes\",\"hi\",\"hid\",\"him\",\"himself\",\"his\",\"hither\",\"home\",\"how\",\"howbeit\",\"however\",\"hundred\",\"i\",\"id\",\"ie\",\"if\",\"i'll\",\"im\",\"immediate\",\"immediately\",\"importance\",\"important\",\"in\",\"inc\",\"indeed\",\"index\",\"information\",\"instead\",\"into\",\"invention\",\"inward\",\"is\",\"isn't\",\"it\",\"itd\",\"it'll\",\"its\",\"itself\",\"i've\",\"j\",\"just\",\"k\",\"keep\tkeeps\",\"kept\",\"kg\",\"km\",\"know\",\"known\",\"knows\",\"l\",\"largely\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"lets\",\"like\",\"liked\",\"likely\",\"line\",\"little\",\"'ll\",\"look\",\"looking\",\"looks\",\"ltd\",\"m\",\"made\",\"mainly\",\"make\",\"makes\",\"many\",\"may\",\"maybe\",\"me\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\"merely\",\"mg\",\"might\",\"million\",\"miss\",\"ml\",\"more\",\"moreover\",\"most\",\"mostly\",\"mr\",\"mrs\",\"much\",\"mug\",\"must\",\"my\",\"myself\",\"n\",\"na\",\"name\",\"namely\",\"nay\",\"nd\",\"near\",\"nearly\",\"necessarily\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"ninety\",\"no\",\"nobody\",\"non\",\"none\",\"nonetheless\",\"noone\",\"nor\",\"normally\",\"nos\",\"not\",\"noted\",\"nothing\",\"now\",\"nowhere\",\"o\",\"obtain\",\"obtained\",\"obviously\",\"of\",\"off\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"omitted\",\"on\",\"once\",\"one\",\"ones\",\"only\",\"onto\",\"or\",\"ord\",\"other\",\"others\",\"otherwise\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"outside\",\"over\",\"overall\",\"owing\",\"own\",\"p\",\"page\",\"pages\",\"part\",\"particular\",\"particularly\",\"past\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\"predominantly\",\"present\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"put\",\"q\",\"que\",\"quickly\",\"quite\",\"qv\",\"r\",\"ran\",\"rather\",\"rd\",\"re\",\"readily\",\"really\",\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\"research\",\"respectively\",\"resulted\",\"resulting\",\"results\",\"right\",\"run\",\"s\",\"said\",\"same\",\"saw\",\"say\",\"saying\",\"says\",\"sec\",\"section\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sent\",\"seven\",\"several\",\"shall\",\"she\",\"shed\",\"she'll\",\"shes\",\"should\",\"shouldn't\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\"significant\",\"significantly\",\"similar\",\"similarly\",\"since\",\"six\",\"slightly\",\"so\",\"some\",\"somebody\",\"somehow\",\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specifically\",\"specified\",\"specify\",\"specifying\",\"still\",\"stop\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\"such\",\"sufficiently\",\"suggest\",\"sup\",\"sure\tt\",\"take\",\"taken\",\"taking\",\"tell\",\"tends\",\"th\",\"than\",\"thank\",\"thanks\",\"thanx\",\"that\",\"that'll\",\"thats\",\"that've\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"thence\",\"there\",\"thereafter\",\"thereby\",\"thered\",\"therefore\",\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"thereto\",\"thereupon\",\"there've\",\"these\",\"they\",\"theyd\",\"they'll\",\"theyre\",\"they've\",\"think\",\"this\",\"those\",\"thou\",\"though\",\"thoughh\",\"thousand\",\"throug\",\"through\",\"throughout\",\"thru\",\"thus\",\"til\",\"tip\",\"to\",\"together\",\"too\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"ts\",\"twice\",\"two\",\"u\",\"un\",\"under\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\"until\",\"unto\",\"up\",\"upon\",\"ups\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\"usefulness\",\"uses\",\"using\",\"usually\",\"v\",\"value\",\"various\",\"'ve\",\"very\",\"via\",\"viz\",\"vol\",\"vols\",\"vs\",\"w\",\"want\",\"wants\",\"was\",\"wasnt\",\"way\",\"we\",\"wed\",\"welcome\",\"we'll\",\"went\",\"were\",\"werent\",\"we've\",\"what\",\"whatever\",\"what'll\",\"whats\",\"when\",\"whence\",\"whenever\",\"where\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"wheres\",\"whereupon\",\"wherever\",\"whether\",\"which\",\"while\",\"whim\",\"whither\",\"who\",\"whod\",\"whoever\",\"whole\",\"who'll\",\"whom\",\"whomever\",\"whos\",\"whose\",\"why\",\"widely\",\"willing\",\"wish\",\"with\",\"within\",\"without\",\"wont\",\"words\",\"world\",\"would\",\"wouldnt\",\"www\",\"x\",\"y\",\"yes\",\"yet\",\"you\",\"youd\",\"you'll\",\"your\",\"youre\",\"yours\",\"yourself\",\"yourselves\",\"you've\",\"z\",\"zero\"]\n",
    "#stopwords = stopwords + [\"player\",\"players\"] # used to build a bi-gram graph without players in it.\n",
    "remove_punct = str.maketrans({key: None for key in string.punctuation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4164\n",
      "4046\n"
     ]
    }
   ],
   "source": [
    "d = pandas.read_csv(\"/Users/michaelshea/Documents/dm_survey_data/dm_survey_clean.csv\", encoding = 'iso-8859-1')\n",
    "tools = [x for x in list(d[\"Top Three Tools\"]) if x == x] # Remove empty responses\n",
    "tips = [x for x in list(d[\"Favorite Trick\"]) if x == x]\n",
    "tips = list(set(tips))\n",
    "tools = list(set(tools))\n",
    "print(len(tools))\n",
    "print(len(tips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kobold fight club</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dungeon masters guide</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monster manual</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donjon</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roll20</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>onenote</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reddit</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>players handbook</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>google docs</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paper</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>photoshop</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>google drive</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>books</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>notebook</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>google</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>evernote</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>core rulebooks</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pencil</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pen</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dice</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>excel</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pen paper</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>index cards</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>graph paper</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fantasy grounds</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>laptop</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dm screen</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>miniatures</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>maps</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>inkarnate</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tool  Freq\n",
       "0       kobold fight club   569\n",
       "1   dungeon masters guide   548\n",
       "2          monster manual   471\n",
       "3                  donjon   449\n",
       "4                  roll20   374\n",
       "5                 onenote   268\n",
       "6                  reddit   209\n",
       "7        players handbook   169\n",
       "8             google docs   135\n",
       "9                   paper   104\n",
       "10              photoshop    82\n",
       "11           google drive    80\n",
       "12                  books    78\n",
       "13               notebook    76\n",
       "14                 google    71\n",
       "15               evernote    68\n",
       "16         core rulebooks    67\n",
       "17                 pencil    65\n",
       "18                    pen    64\n",
       "19                   dice    58\n",
       "20                  excel    57\n",
       "21              pen paper    54\n",
       "22            index cards    48\n",
       "23            graph paper    47\n",
       "24        fantasy grounds    40\n",
       "25                 laptop    39\n",
       "26              dm screen    38\n",
       "27             miniatures    37\n",
       "28                   maps    36\n",
       "29              inkarnate    36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tool_list = []\n",
    "unprocessed_count = 0\n",
    "stop_words = [\"the\",\"and\"]\n",
    "for response in tools:\n",
    "    try:\n",
    "        response = response.replace(\"\\n\",\",\") # turn line breaks into commas\n",
    "    except:\n",
    "        meh = 1\n",
    "    tool_set = response.split(\",\")\n",
    "    for tool in tool_set:\n",
    "        # Bunch of replacements to normalize on common tools\n",
    "        tool = tool.strip().lower()\n",
    "        tool = \" \".join([x for x in tool.split() if x not in stop_words])\n",
    "        tool = tool.replace(\".\",\"\")\n",
    "        tool = tool.replace(\"'\",\"\")\n",
    "        tool = tool.replace(\"dmg\",\"dungeon masters guide\")\n",
    "        tool = tool.replace(\"dungeon master guide\",\"dungeon masters guide\")\n",
    "        tool = tool.replace(\"mm\",\"monster manual\")\n",
    "        tool = tool.replace(\"monster manuel\",\"monster manual\")\n",
    "        tool = tool.replace(\"monsters manual\",\"monster manual\")\n",
    "        tool = tool.replace(\"dm guide\",\"dungeon masters guide\")\n",
    "        tool = tool.replace(\"dms guide\",\"dungeon masters guide\")\n",
    "        tool = tool.replace(\"core books\",\"core rulebooks\")\n",
    "        tool = tool.replace(\"phb\",\"players handbook\")\n",
    "        tool = tool.replace(\"phb\",\"players handbook\")\n",
    "        tool = tool.replace(\"roll 20\",\"roll20\")\n",
    "        tool = tool.replace(\"one note\",\"onenote\")\n",
    "        tool = tool.replace(\"donjonbinsh\",\"donjon\")\n",
    "        tool = tool.replace(\"microsoft onenote\",\"onenote\")\n",
    "        tool = tool.replace(\"koboldclub\",\"kobold fight club\")\n",
    "        tool = tool.replace(\"player handbook\",\"players handbook\")\n",
    "        tool = tool.replace(\"core rule books\",\"core rulebooks\")\n",
    "#        if \"kobold\" in tool.split() and \"fight\" in tool.split(): tool = \"kobold fight club\"\n",
    "        if \"donjon\" in tool: tool = \"donjon\"\n",
    "        if \"kobold\" in tool and \"fight\" in tool: tool = \"kobold fight club\"\n",
    "        if \"dungeon masters guide\" in tool: tool = \"dungeon masters guide\"\n",
    "        if \"monster manual\" in tool: tool = \"monster manual\"\n",
    "        if \"players handbook\" in tool: tool = \"players handbook\"\n",
    "        if tool != \"\": # get rid of blank entries\n",
    "            my_tool_list.append(tool)\n",
    "c = Counter(my_tool_list)\n",
    "p = pandas.DataFrame(list(c.most_common(5000)))\n",
    "p.columns = [\"Tool\",\"Freq\"]\n",
    "p = p[p[\"Freq\"] >= 2]\n",
    "p.to_csv(\"/Users/michaelshea/Documents/dm_survey_data/2016_dm_survey_tools.csv\")\n",
    "p.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_word_count_df(list_of_texts):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    words = [x.split() for x in list_of_texts] # Turn each response into a list of words\n",
    "    words = list(itertools.chain.from_iterable(words)) # Flatten the words into a single list of all words\n",
    "    words = [wordnet_lemmatizer.lemmatize(x.lower().translate(remove_punct)) for x in words \n",
    "             if x.lower().translate(remove_punct) not in stopwords \n",
    "             and x.lower().translate(remove_punct) != \"\"] # Remove stopwords, punctuation and lower case everything.\n",
    "    c = Counter(words) # build a counter to count up word frequency\n",
    "    pd = pandas.DataFrame(c.most_common(500000)) # Give us the top 500 words and turn into a Pandas dataframe\n",
    "    pd.columns = [\"word\",\"Freq\"] # Set the columns\n",
    "    return(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player (2044), story (522), character (461), game (425), npc (410), dont (350), fun (278), thing (271), session (254), keep (244), time (233), encounter (217), will (205), pc (199), combat (198), play (175), idea (173), good (163), sure (153), adventure (148), rule (142), feel (138), roll (137), lot (135), party (131), making (130), action (129), plan (127), plot (127), dm (123), work (120), campaign (119), great (112), improv (110), going (101), create (99), group (93), improvise (93), choice (90), help (89), trick (86), monster (85), prep (84), find (83), build (83), letting (80), music (80), happen (80), table (79), prepare (79), "
     ]
    }
   ],
   "source": [
    "wc = get_word_count_df(tips).head(50)\n",
    "for x in wc.iterrows():\n",
    "    print(x[1][\"word\"] + \" (\" + str(x[1][\"Freq\"]) + \"), \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player character (54), player will (51), letting player (49), listen player (42), player story (39), making sure (38), player feel (32), player game (32), player dont (31), sure player (30), player action (29), keep player (29), player idea (28), dont afraid (27), game player (27), player fun (27), allow player (26), player choice (26), story player (25), keep thing (25), combat encounter (25), role play (22), character story (21), knowing player (19), player decide (19), player agency (19), random encounter (18), player play (18), player find (18), thing player (17), rule cool (17), fun player (17), player thing (17), listening player (17), drive story (16), ahead time (16), magic item (16), player describe (15), plot twist (15), plot point (15), npc player (15), player going (15), memorable npc (14), role playing (14), player engaged (14), player control (14), plot hook (14), side quest (14), spend time (14), dm screen (13), \n",
      "\n",
      "keep thing moving (13), player drive story (11), making sure player (11), making sure fun (6), sure player fun (6), pay attention player (6), allow player freedom (5), spend lot time (5), player write story (5), player guide story (5), player character story (5), random encounter table (4), game player play (4), keep flow going (4), keep action moving (4), dont sweat small (4), keep thing interesting (4), listen player idea (4), fudge dice roll (4), sweat small stuff (4), player role play (4), letting player story (4), player feel character (4), great dd game (4), player develop story (4), player feel awesome (4), keep player engaged (4), pop culture reference (3), skill check player (3), dm screen initiative (3), dont afraid change (3), player decision matter (3), consequence player action (3), character moment shine (3), solution letting player (3), idea session will (3), open communication player (3), preparation preparation preparation (3), flying seat pant (3), player emotionally invested (3), character dont afraid (3), music help set (3), player find kind (3), change thing fly (3), great game player (3), sure player engaged (3), list name npc (3), list npc name (3), dont rule lawyer (3), dont afraid player (3), "
     ]
    }
   ],
   "source": [
    "def get_bigrams_trigrams_df(list_of_texts):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    word_sets = [x.lower().translate(remove_punct).split() for x in list_of_texts]\n",
    "    total_word_sets = []\n",
    "    for word_set in word_sets:\n",
    "        new_word_set = []\n",
    "        for word in word_set:\n",
    "            if word not in stopwords:\n",
    "                new_word_set.append(wordnet_lemmatizer.lemmatize(word))\n",
    "        total_word_sets.append(new_word_set)\n",
    "    bigrams = list(itertools.chain.from_iterable(list(list(nltk.ngrams(x, 2) for x in total_word_sets))))\n",
    "    bigrams_df = pandas.DataFrame(Counter(bigrams).most_common(100000), columns = [\"trigram\", \"freq\"])\n",
    "    trigrams = list(itertools.chain.from_iterable(list(list(nltk.ngrams(x, 3) for x in total_word_sets))))\n",
    "    trigrams_df = pandas.DataFrame(Counter(trigrams).most_common(100000), columns = [\"trigram\", \"freq\"])\n",
    "    return(bigrams, bigrams_df, trigrams_df)\n",
    "\n",
    "# Print out nice paragraphs of top 50 bigrams and trigrams\n",
    "bigrams, bigram_frame, trigram_frame = get_bigrams_trigrams_df(tips)\n",
    "tf = trigram_frame.head(50)\n",
    "\n",
    "bf = bigram_frame.head(50)\n",
    "for x in bf.iterrows():\n",
    "    replacements = [\"(\",\")\",\",\",\"'\"]\n",
    "    print(\"\".join([y for y in str(x[1][\"trigram\"]) if y not in replacements]) + \n",
    "          \" (\" + str(x[1][\"freq\"]) + \"), \", end=\"\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for x in tf.iterrows():\n",
    "    replacements = [\"(\",\")\",\",\",\"'\"]\n",
    "    print(\"\".join([y for y in str(x[1][\"trigram\"]) if y not in replacements]) + \n",
    "          \" (\" + str(x[1][\"freq\"]) + \"), \", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output survey tip word count CSV\n",
    "tips_wc_pd = get_word_count_df(tips)\n",
    "tips_wc_pd.to_csv(\"/Users/michaelshea/Documents/dm_survey_data/2016_dm_survey_tip_word_count.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output bigrams spreadsheets both frequency rollup and a flat one for the graph.\n",
    "bigrams, bigram_frame, trigram_frame = get_bigrams_trigrams_df(tools)\n",
    "pandas.DataFrame(bigrams).to_csv(\"/Users/michaelshea/Documents/dm_survey_data/2016_dm_survey_tip_bigrams.csv\", index=False)\n",
    "bigram_frame = bigram_frame[bigram_frame[\"freq\"] >= 2] # reduce the csv to only those that show up twice\n",
    "bigram_frame.to_csv(\"/Users/michaelshea/Documents/dm_survey_data/2016_dm_survey_bigram_rollup.csv\", index=False)\n",
    "trigram_frame = trigram_frame[trigram_frame[\"freq\"] >= 2] # reduce the csv to only those that show up twice\n",
    "trigram_frame.to_csv(\"/Users/michaelshea/Documents/dm_survey_data/2016_dm_survey_trigram_rollup.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stripped_tips = [x.replace(\"\\n\",\" \") for x in tips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/michaelshea/Documents/dm_survey_data/tips.txt\",\"w\") as f:\n",
    "    for tip in stripped_tips:\n",
    "        f.write(tip)\n",
    "        f.write(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
